{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Linear_Regression (Pseudo_Inverse).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarshanPatel0919/Machine-Learning/blob/master/Linear_Regression_(Pseudo_Inverse).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktd5vbPLbAPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " ######################        Q.1         ##############################\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "t = np.linspace(-10,10,201)\n",
        "l = t*t;\n",
        "s\n",
        "t_best = np.where(l == np.min(l))\n",
        "best = [float(t[t_best[0]])]\n",
        "print('Minima of the given Function is at : theta =',best[0])\n",
        "\n",
        "plt.plot(t,l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzKXmCZMbAPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################        Q.2         ##############################\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "t = np.linspace(-10,10,201)\n",
        "\n",
        "l = [[i*i + j*j for i in t] for j in t]\n",
        "l = np.asarray(l)\n",
        "\n",
        "t_best = np.where(l == np.min(l))\n",
        "best = [float(t[t_best[0]]),float(t[t_best[1]])]\n",
        "print('Minima of the given Function is at : theta0 =',best[0],'theta1 =',best[1])\n",
        "\n",
        "t0,t1 = np.meshgrid(t,t)\n",
        "#this also works fine but for complex function method used above(converting list to ndarray) is better\n",
        "#l = t0*t0 + t1*t1\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.plot_surface(t0,t1,l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc2dfT-QbAPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################        Q.3         ##############################\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "res = pd.read_csv('data.csv')\n",
        "\n",
        "\n",
        "x=np.asarray(res['x'])\n",
        "x = (x - np.mean(x))/np.std(x)\n",
        "y=np.asarray(res['y'])\n",
        "\n",
        "t= np.linspace(-50,50,1001)\n",
        "l = [[ np.sum((y - t0 - x*t1)**2)/len(x) for t1 in t ] for t0 in t]\n",
        "l = np.asarray(l)\n",
        "\n",
        "t_best = np.where(l == np.min(l))\n",
        "best = [float(t[t_best[0]]),float(t[t_best[1]])]\n",
        "print('Minima of the Cost Function in the graph is at : theta0 =',best[0],'theta1 =',best[1])\n",
        "print('Minimum value of Cost function in the graph is :',np.min(l),'\\n')\n",
        "\n",
        "t0,t1=np.meshgrid(t,t);\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.plot_surface(t0,t1,l)\n",
        "\n",
        "######################        Q.4         ##############################\n",
        "\n",
        "x=np.asarray([[1,i] for i in x])\n",
        "theta = np.matmul(np.matmul(np.linalg.inv(np.matmul(np.transpose(x),x)),np.transpose(x)),y)\n",
        "\n",
        "print('Psuedo inverse(Least Square-LS) method : theta0 =',theta[0],'theta1 =',theta[1])\n",
        "\n",
        "######################        Q.5         ##############################\n",
        "import random\n",
        "\n",
        "x= np.asarray([i[1] for i in x])\n",
        "l_theta = (np.sum((y - theta[0] - x*theta[1])**2))/len(x)\n",
        "\n",
        "print('Psuedo Inverse method : Value of Cost Function =',l_theta,'\\n')\n",
        "          \n",
        "theta_random = [random.randrange(-500,500,1)/10,random.randrange(-500,500,1)/10]\n",
        "#range is (-50,50) step value is 0.1 but ranrange doesn't allow non-integer stepvalues\n",
        "l_theta_random = (np.sum((y - theta_random[0] - x*theta_random[1])**2))/len(x)\n",
        "\n",
        "print('Choosing random theta : Value of Cost Function =',l_theta_random,'\\n')\n",
        "      \n",
        "print(\"\"\"Conclusion: For any random value of theta,it\\'s Cost Function will be grater than or equal to ; Value of\n",
        "            Cost Function for Theta found by Psuedo Inverse method,hence it is called Least Square(LS) Method.\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}